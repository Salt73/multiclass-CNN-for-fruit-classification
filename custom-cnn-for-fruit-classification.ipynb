{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7233062,"sourceType":"datasetVersion","datasetId":4188329}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Define the data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, validation_split=0.2)\nVal_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory('/kaggle/input/shitpy/dataset/train', target_size=(64, 64), batch_size=32, class_mode='categorical', subset='training')\nVal_generator = train_datagen.flow_from_directory('/kaggle/input/shitpy/dataset/train', target_size=(64, 64), batch_size=32, class_mode='categorical', subset='validation')\n\n# Define the model\nmodel = Sequential()\n\n# Convolutional layers\nmodel.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flatten layer to transition from convolutional to fully connected layers\nmodel.add(Flatten())\n\n# Fully connected layers\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))  # 5 classes, so the output layer has 5 neurons with softmax activation\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Display the model summary\nmodel.summary()\n\n# Train the model\nmodel.fit(train_generator, epochs=15, steps_per_epoch=len(train_generator), validation_data=Val_generator, validation_steps=len(Val_generator))\nmodel.save('classification_net.h5')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-24T15:35:52.960469Z","iopub.execute_input":"2023-12-24T15:35:52.961414Z","iopub.status.idle":"2023-12-24T15:41:11.391128Z","shell.execute_reply.started":"2023-12-24T15:35:52.961366Z","shell.execute_reply":"2023-12-24T15:41:11.390122Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Found 7920 images belonging to 5 classes.\nFound 1980 images belonging to 5 classes.\nModel: \"sequential_5\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_15 (Conv2D)          (None, 62, 62, 32)        896       \n                                                                 \n max_pooling2d_15 (MaxPooli  (None, 31, 31, 32)        0         \n ng2D)                                                           \n                                                                 \n dropout_20 (Dropout)        (None, 31, 31, 32)        0         \n                                                                 \n conv2d_16 (Conv2D)          (None, 29, 29, 64)        18496     \n                                                                 \n max_pooling2d_16 (MaxPooli  (None, 14, 14, 64)        0         \n ng2D)                                                           \n                                                                 \n dropout_21 (Dropout)        (None, 14, 14, 64)        0         \n                                                                 \n conv2d_17 (Conv2D)          (None, 12, 12, 128)       73856     \n                                                                 \n max_pooling2d_17 (MaxPooli  (None, 6, 6, 128)         0         \n ng2D)                                                           \n                                                                 \n dropout_22 (Dropout)        (None, 6, 6, 128)         0         \n                                                                 \n flatten_5 (Flatten)         (None, 4608)              0         \n                                                                 \n dense_10 (Dense)            (None, 512)               2359808   \n                                                                 \n dropout_23 (Dropout)        (None, 512)               0         \n                                                                 \n dense_11 (Dense)            (None, 5)                 2565      \n                                                                 \n=================================================================\nTotal params: 2455621 (9.37 MB)\nTrainable params: 2455621 (9.37 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2023-12-24 15:36:02.833624: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_5/dropout_20/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"248/248 [==============================] - 36s 136ms/step - loss: 1.2626 - accuracy: 0.4472 - val_loss: 1.2485 - val_accuracy: 0.4566\nEpoch 2/10\n248/248 [==============================] - 29s 116ms/step - loss: 1.0661 - accuracy: 0.5645 - val_loss: 1.2102 - val_accuracy: 0.4818\nEpoch 3/10\n248/248 [==============================] - 29s 116ms/step - loss: 0.9791 - accuracy: 0.6018 - val_loss: 1.1956 - val_accuracy: 0.4919\nEpoch 4/10\n248/248 [==============================] - 29s 116ms/step - loss: 0.9353 - accuracy: 0.6246 - val_loss: 1.0745 - val_accuracy: 0.5439\nEpoch 5/10\n248/248 [==============================] - 29s 118ms/step - loss: 0.9010 - accuracy: 0.6420 - val_loss: 1.0480 - val_accuracy: 0.5712\nEpoch 6/10\n248/248 [==============================] - 29s 116ms/step - loss: 0.8787 - accuracy: 0.6503 - val_loss: 1.0325 - val_accuracy: 0.5798\nEpoch 7/10\n248/248 [==============================] - 29s 115ms/step - loss: 0.8605 - accuracy: 0.6640 - val_loss: 1.0224 - val_accuracy: 0.5879\nEpoch 8/10\n248/248 [==============================] - 29s 117ms/step - loss: 0.8255 - accuracy: 0.6807 - val_loss: 1.0071 - val_accuracy: 0.5955\nEpoch 9/10\n248/248 [==============================] - 30s 120ms/step - loss: 0.8145 - accuracy: 0.6797 - val_loss: 0.9702 - val_accuracy: 0.6051\nEpoch 10/10\n248/248 [==============================] - 29s 118ms/step - loss: 0.7854 - accuracy: 0.6973 - val_loss: 1.0148 - val_accuracy: 0.6015\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = keras.models.load_model('classification_net.h5')\n\nunlabeled_data_dir = '/kaggle/input/shitpy/dataset/test'\n# putting images in a list\nunlabeled_images = os.listdir(unlabeled_data_dir)\n\nunlabeled_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\nunlabeled_generator = unlabeled_datagen.flow_from_dataframe(\n    pd.DataFrame({'Image': unlabeled_images}),\n    directory=unlabeled_data_dir,\n    x_col='Image',\n    y_col=None,\n    class_mode=None,\n    target_size=(64, 64),\n    batch_size=32,\n    shuffle=False \n)\n\n# Predictions\npredictions = model.predict(unlabeled_generator)\n\n# Assign predictions to it's classes\npredicted_labels = np.argmax(predictions, axis=1)\n\npredictions_df = pd.DataFrame({\n    'Image': unlabeled_generator.filenames,\n    'Predicted_Label': predicted_labels\n})\n\ncsv_save_path = 'unlabeled_predictions.csv'\npredictions_df.to_csv(\"CRY.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T15:41:11.393299Z","iopub.execute_input":"2023-12-24T15:41:11.393686Z","iopub.status.idle":"2023-12-24T15:41:12.189961Z","shell.execute_reply.started":"2023-12-24T15:41:11.393650Z","shell.execute_reply":"2023-12-24T15:41:12.189090Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Found 100 validated image filenames.\n4/4 [==============================] - 0s 47ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/CRY.csv')\nv = df.rename(columns = {'Image':'image_id','Predicted_Label':'label'})","metadata":{"execution":{"iopub.status.busy":"2023-12-24T15:41:12.192494Z","iopub.execute_input":"2023-12-24T15:41:12.192781Z","iopub.status.idle":"2023-12-24T15:41:12.199959Z","shell.execute_reply.started":"2023-12-24T15:41:12.192755Z","shell.execute_reply":"2023-12-24T15:41:12.199186Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"v.to_csv('CRY.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T15:41:12.202069Z","iopub.execute_input":"2023-12-24T15:41:12.202697Z","iopub.status.idle":"2023-12-24T15:41:12.212058Z","shell.execute_reply.started":"2023-12-24T15:41:12.202661Z","shell.execute_reply":"2023-12-24T15:41:12.211159Z"},"trusted":true},"execution_count":32,"outputs":[]}]}